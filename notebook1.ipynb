{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection Algorithms: A Visit  \n",
    "## Why look at this problem?  \n",
    "When I was working for my former employer, a digital advertising company in Japan, there were from time to time some anomaly detection tasks assigned to me which I did not feel very involved in such tasks. As I can remember, I just threw all the data into some model like [Gaussian Processes](https://bugra.github.io/work/notes/2014-05-11/robust-regression-and-outlier-detection-via-gaussian-processes/) and high-lighted all the data which are not in the confidence/prediction interval as the output. I did not think much about if I can explain the results but I was wrong. Indeed, feature engineering is important when you are dealing with data, and there are many powerful models that can handle imbalanced data or outliers very well like gaussian processes or boosted trees. However in most cases, those \"outliers\" do not only concern us in a data engineering way, but also in business sense. Which, requires the analysts to do more research about this specific problem and provides insights about our data.  \n",
    "Recently I read about a Q&A post on [Zhihu (a Quora-like site in China)](https://www.zhihu.com/question/280696035), the question is \"What are the popular anomaly detection algorithms in data mining?\". I went through all the answers and found that there are lot of stuff in this field. So I decided to look at this problem by implementing different methods myself. Could be lot of fun :)  \n",
    "\n",
    "## Some tools/libraries I will be using  \n",
    "- JupyterLab\n",
    "- pandas / dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection  \n",
    "This is a kaggle dataset, problem description goes [here](https://www.kaggle.com/mlg-ulb/creditcardfraud/version/3#). Some notes:  \n",
    "- Binary classification problem\n",
    "- Use AUC as the performance metric\n",
    "- Highly unbalanced:  frauds account takes for 0.172% of all transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n",
      "492 284807\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Okay let's take a look at the data first.\n",
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./creditcard.csv', header=0)\n",
    "print (list(df.columns))\n",
    "print (len(df.loc[df['Class']==1]), len(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
