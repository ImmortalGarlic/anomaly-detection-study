{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n",
      "492 284807\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Okay let's take a look at the data first.\n",
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../fraud/creditcard.csv', header=0)\n",
    "cols = list(df.columns)\n",
    "# Row numbers of fraud records\n",
    "fraud_idx = list(df.loc[df['Class']==1].index.values)\n",
    "\n",
    "print (cols)\n",
    "print (len(fraud_idx), len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Approaches  \n",
    "First I would like to try some unsupervised learning algorithms (pure statistical methods or clustering) and compare with their labels. By the end of this part hope I can have a general understanding of things below:  \n",
    "- How to implement unsupervised learning algorithms on anomaly detection  \n",
    "- What the data is like in specific problem and why some algorithms perfrom well  \n",
    "- Prons and cons of each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Prepare our data first\n",
    "'''\n",
    "\n",
    "df_nolabel = df[cols[:-1]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1　KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "def kmeans_ad(df, clusters, fraud_idx):\n",
    "    # normalize 'Time' and 'Amount'\n",
    "    time_col = list(df_1['Time'])\n",
    "    time_max = max(time_col)\n",
    "    time_col = [x/time_max for x in time_col]\n",
    "\n",
    "    amount_col = list(df_1['Amount'])\n",
    "    amount_max = max(amount_col)\n",
    "    amount_col = [x/amount_max for x in amount_col]\n",
    "\n",
    "    df_1['Time'] = time_col\n",
    "    df_1['Amount'] = amount_col\n",
    "\n",
    "    X = df_1.as_matrix()\n",
    "    kmeans = KMeans(n_clusters=clusters, random_state=0).fit(X)\n",
    "    labels = list(kmeans.labels_)\n",
    "    centers = list(kmeans.cluster_centers_)\n",
    "    \n",
    "    clustered_labels = []\n",
    "    for idx in fraud_idx:\n",
    "        clustered_labels.append(labels[idx])\n",
    "    \n",
    "    clustered_dict = {}\n",
    "    for c in clustered_labels:\n",
    "        if c not in clustered_dict:\n",
    "            clustered_dict[c] = 1\n",
    "        else:\n",
    "            clustered_dict[c] += 1\n",
    "            \n",
    "    return clustered_dict, centers, labels, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 492}\n"
     ]
    }
   ],
   "source": [
    "cluster_dict, centers, labels, X = kmeans_ad(df_1, 1, fraud_idx)\n",
    "print (cluster_dict)\n",
    "distances = [np.linalg.norm(X[idx] - centers[labels[idx]]) for idx in range(len(labels))]\n",
    "distandes_sorted = sorted(distances, reverse=True)\n",
    "rank = []\n",
    "for f in fraud_idx:\n",
    "    rank.append(distandes_sorted.index(distances[f]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes  \n",
    "- KMeans itself is sentitive to outliers\n",
    "- To ensure a good detection result first you need a good clustering result\n",
    "    - [StackExchange](https://stats.stackexchange.com/questions/160260/anomaly-detection-based-on-clustering)\n",
    "- Maybe try density-based clustering?\n",
    "    - [Unsupervised clustering approach for network anomaly detection](https://pdfs.semanticscholar.org/7d5d/794e77378a7dbc5d67d79f4c5e7a11b05454.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2　DBSCAN  \n",
    "Density-based spatial clustering of applications with noise. This approach evaluates the density of data points and groups them based on high/low densities. This approach is very robust to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
